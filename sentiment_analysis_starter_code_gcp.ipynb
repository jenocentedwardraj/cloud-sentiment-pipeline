{"cells": [{"cell_type": "markdown", "metadata": {"id": "zJcwCcshefqD"}, "source": "# Sentiment Analysis of Customer Feedback - PySpark Starter Code\nThis notebook demonstrates how to process, train, and evaluate a machine learning model for sentiment analysis of customer feedback using PySpark."}, {"cell_type": "code", "execution_count": 1, "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "DCdx5xm4ezzl", "outputId": "db91c8c9-b359-4eeb-db35-2268b79d27a9", "tags": []}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Running in Colab: False\n"}], "source": "import sys\nIN_COLAB = 'google.colab' in sys.modules\nprint(\"Running in Colab:\", IN_COLAB)"}, {"cell_type": "code", "execution_count": 2, "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "0hQwgqhbeztX", "outputId": "01c7bfab-e8be-40c9-fa20-48dbc9ff69cb", "tags": []}, "outputs": [], "source": "# !pip install pyspark  # Already preinstalled on Dataproc\n# gcsfs not needed in Dataproc"}, {"cell_type": "code", "execution_count": 3, "metadata": {"id": "FTnRF_CBezl9", "tags": []}, "outputs": [], "source": "#from google.colab import auth\n#auth.authenticate_user()"}, {"cell_type": "code", "execution_count": 4, "metadata": {"id": "ecspLDbkezeS", "tags": []}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "Setting default log level to \"WARN\".\nTo adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n25/06/23 17:29:45 INFO SparkEnv: Registering MapOutputTracker\n25/06/23 17:29:45 INFO SparkEnv: Registering BlockManagerMaster\n25/06/23 17:29:45 INFO SparkEnv: Registering BlockManagerMasterHeartbeat\n25/06/23 17:29:45 INFO SparkEnv: Registering OutputCommitCoordinator\n"}], "source": "from pyspark.sql import SparkSession\n\nspark = SparkSession.builder \\\n    .appName(\"Sentiment Analysis\") \\\n    .getOrCreate()"}, {"cell_type": "code", "execution_count": 5, "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "SvmwjN6_ezVt", "outputId": "e4bb97fc-9f6a-42ff-d360-b798f7ec5344", "tags": []}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "[Stage 2:>                                                          (0 + 1) / 1]\r"}, {"name": "stdout", "output_type": "stream", "text": "+---------------+--------------------+---------------+-------------+----------------+-------------------+--------------------+-------------------+-------+\n|Sentiment_Score|       Feedback_Text|Feedback_Length|Response_Time|Customer_Segment|Interaction_Channel|           Survey_ID|         Time_Stamp|Country|\n+---------------+--------------------+---------------+-------------+----------------+-------------------+--------------------+-------------------+-------+\n|              1|Excellent experience|             20|        56.85|         Premium|               Chat|668688ad-9965-4cb...|2024-03-13 03:26:41|  India|\n|              1|       Great service|             13|        55.55|         Premium|              Phone|1be3fb37-03c8-488...|2024-04-27 12:46:59| Canada|\n|              2|    Agent was polite|             16|        33.67|         Premium|              Phone|0efd4a67-ab8c-4c0...|2024-03-26 02:02:44| Canada|\n|              1|          Quick help|             10|        12.65|        Standard|              Email|c607263b-d183-464...|2024-04-15 21:37:20|  India|\n|              2|Excellent experience|             20|        53.84|         Premium|              Email|998606a3-d2ba-4f7...|2024-04-28 20:10:59|Germany|\n+---------------+--------------------+---------------+-------------+----------------+-------------------+--------------------+-------------------+-------+\nonly showing top 5 rows\n\nroot\n |-- Sentiment_Score: integer (nullable = true)\n |-- Feedback_Text: string (nullable = true)\n |-- Feedback_Length: integer (nullable = true)\n |-- Response_Time: double (nullable = true)\n |-- Customer_Segment: string (nullable = true)\n |-- Interaction_Channel: string (nullable = true)\n |-- Survey_ID: string (nullable = true)\n |-- Time_Stamp: timestamp (nullable = true)\n |-- Country: string (nullable = true)\n\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "# Load the CSV directly from GCS (no need to download locally on Dataproc)\nbucket_name = \"cis-415-project-jedwardr\"\n# file_name = \"sentiment_small_dataset.csv\"\nfile_name = \"sentiment_big_dataset.csv\"\ngcs_path = f\"gs://{bucket_name}/{file_name}\"\n\ndf = spark.read.csv(gcs_path, header=True, inferSchema=True)\ndf.show(5)\ndf.printSchema()"}, {"cell_type": "code", "execution_count": 6, "metadata": {"id": "xcCF-fffefqF", "tags": []}, "outputs": [], "source": "# Import required libraries\nfrom pyspark.sql import SparkSession\nfrom pyspark.ml.feature import Tokenizer, CountVectorizer, StringIndexer\nfrom pyspark.ml import Pipeline\nfrom pyspark.ml.classification import LogisticRegression, NaiveBayes\nfrom pyspark.ml.evaluation import MulticlassClassificationEvaluator\nfrom pyspark.sql.functions import col"}, {"cell_type": "code", "execution_count": 7, "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "Cum-A87AefqH", "outputId": "a2821dd7-565b-4113-c805-f0716580e5fc", "tags": []}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "25/06/23 17:32:43 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n                                                                                \r"}, {"name": "stdout", "output_type": "stream", "text": "+-------+------------------+------------------+-----------------+------------------+----------------+-------------------+--------------------+-------+\n|summary|   Sentiment_Score|     Feedback_Text|  Feedback_Length|     Response_Time|Customer_Segment|Interaction_Channel|           Survey_ID|Country|\n+-------+------------------+------------------+-----------------+------------------+----------------+-------------------+--------------------+-------+\n|  count|           1000000|           1000000|          1000000|            989998|         1000000|            1000000|             1000000|1000000|\n|   mean|          1.300932|              NULL|       117.620502|30.494507645470332|            NULL|               NULL|                NULL|   NULL|\n| stddev|0.7807307736451352|              NULL|996.3299336929379| 17.02967640897917|            NULL|               NULL|                NULL|   NULL|\n|    min|                 0|  Agent was polite|               10|               1.0|           Basic|               Chat|000007c2-9695-4d6...| Canada|\n|    max|                 2|Very slow response|            10000|              60.0|        Standard|              Phone|fffffc76-fc7d-41a...|    USA|\n+-------+------------------+------------------+-----------------+------------------+----------------+-------------------+--------------------+-------+\n\n+---------------+-------------+---------------+-------------+----------------+-------------------+---------+----------+-------+\n|Sentiment_Score|Feedback_Text|Feedback_Length|Response_Time|Customer_Segment|Interaction_Channel|Survey_ID|Time_Stamp|Country|\n+---------------+-------------+---------------+-------------+----------------+-------------------+---------+----------+-------+\n|          false|        false|          false|        false|           false|              false|    false|     false|  false|\n|          false|        false|          false|        false|           false|              false|    false|     false|  false|\n|          false|        false|          false|        false|           false|              false|    false|     false|  false|\n|          false|        false|          false|        false|           false|              false|    false|     false|  false|\n|          false|        false|          false|        false|           false|              false|    false|     false|  false|\n|          false|        false|          false|        false|           false|              false|    false|     false|  false|\n|          false|        false|          false|        false|           false|              false|    false|     false|  false|\n|          false|        false|          false|        false|           false|              false|    false|     false|  false|\n|          false|        false|          false|        false|           false|              false|    false|     false|  false|\n|          false|        false|          false|        false|           false|              false|    false|     false|  false|\n|          false|        false|          false|        false|           false|              false|    false|     false|  false|\n|          false|        false|          false|        false|           false|              false|    false|     false|  false|\n|          false|        false|          false|        false|           false|              false|    false|     false|  false|\n|          false|        false|          false|        false|           false|              false|    false|     false|  false|\n|          false|        false|          false|        false|           false|              false|    false|     false|  false|\n|          false|        false|          false|        false|           false|              false|    false|     false|  false|\n|          false|        false|          false|        false|           false|              false|    false|     false|  false|\n|          false|        false|          false|        false|           false|              false|    false|     false|  false|\n|          false|        false|          false|        false|           false|              false|    false|     false|  false|\n|          false|        false|          false|        false|           false|              false|    false|     false|  false|\n+---------------+-------------+---------------+-------------+----------------+-------------------+---------+----------+-------+\nonly showing top 20 rows\n\n"}], "source": "# Exploratory Data Analysis (EDA)\ndf.describe().show()\n# Check for missing values\ndf.select([col(c).isNull().alias(c) for c in df.columns]).show()"}, {"cell_type": "code", "execution_count": 8, "metadata": {"id": "DS66yLepefqH", "tags": []}, "outputs": [], "source": "# Data Preprocessing\ndf = df.na.drop()  # Drop rows with null values\ndf = df.withColumn('Sentiment_Score', col('Sentiment_Score').cast('int'))  # Ensure target is int\n# Tokenizing the 'Feedback_Text' column\ntokenizer = Tokenizer(inputCol='Feedback_Text', outputCol='words')\n# Vectorizing the words column\nvectorizer = CountVectorizer(inputCol='words', outputCol='features')\n# Indexing the target variable 'Sentiment_Score'\nindexer = StringIndexer(inputCol='Sentiment_Score', outputCol='label')"}, {"cell_type": "code", "execution_count": 9, "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "UWMI7FAgefqI", "outputId": "24a796e2-159d-4fa4-b28d-e8957151699a", "tags": []}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "[Stage 7:>                                                          (0 + 1) / 1]\r"}, {"name": "stdout", "output_type": "stream", "text": "+---------------+----------------+---------------+-------------+----------------+-------------------+--------------------+-------------------+-------+\n|Sentiment_Score|   Feedback_Text|Feedback_Length|Response_Time|Customer_Segment|Interaction_Channel|           Survey_ID|         Time_Stamp|Country|\n+---------------+----------------+---------------+-------------+----------------+-------------------+--------------------+-------------------+-------+\n|              0|Agent was polite|             16|         1.01|        Standard|              Phone|c96bd065-dc67-430...|2024-02-21 01:53:19|     UK|\n|              0|Agent was polite|             16|         1.02|         Premium|               Chat|ec83b2d2-8941-4b2...|2024-01-11 10:21:44|  India|\n|              0|Agent was polite|             16|         1.02|        Standard|              Phone|731888f4-b02b-4b1...|2024-02-05 14:14:00|  India|\n|              0|Agent was polite|             16|         1.03|           Basic|              Phone|eec74722-f10a-458...|2024-05-03 03:28:22|    USA|\n|              0|Agent was polite|             16|         1.03|         Premium|              Email|e2c8ad5a-4b9e-45b...|2024-02-11 18:27:44| Canada|\n+---------------+----------------+---------------+-------------+----------------+-------------------+--------------------+-------------------+-------+\nonly showing top 5 rows\n\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "# Train/Test Split\ntrain_df, test_df = df.randomSplit([0.8, 0.2], seed=42)\ntrain_df.show(5)"}, {"cell_type": "code", "execution_count": 10, "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "jU6-qvQqefqI", "outputId": "7d6ca9b5-476c-4ebf-9ec4-3281bd6a15d9", "tags": []}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "[Stage 27:>                                                         (0 + 1) / 1]\r"}, {"name": "stdout", "output_type": "stream", "text": "+----------------+---------------+----------+\n|   Feedback_Text|Sentiment_Score|prediction|\n+----------------+---------------+----------+\n|Agent was polite|              0|       0.0|\n|Agent was polite|              0|       0.0|\n|Agent was polite|              0|       0.0|\n|Agent was polite|              0|       0.0|\n|Agent was polite|              0|       0.0|\n+----------------+---------------+----------+\nonly showing top 5 rows\n\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "# Train Logistic Regression Model\nlr = LogisticRegression(maxIter=10, regParam=0.01)\nlr_pipeline = Pipeline(stages=[tokenizer, vectorizer, indexer, lr])\n\nlr_model = lr_pipeline.fit(train_df)\nlr_predictions = lr_model.transform(test_df)\n\nlr_predictions.select('Feedback_Text', 'Sentiment_Score', 'prediction').show(5)"}, {"cell_type": "code", "execution_count": 11, "metadata": {"id": "ARpHvBguefqI", "tags": []}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "# Train Naive Bayes Model\nnb = NaiveBayes(modelType='multinomial', labelCol='label', featuresCol='features')\nnb_pipeline = Pipeline(stages=[tokenizer, vectorizer, indexer, nb])\n\nnb_model = nb_pipeline.fit(train_df)\nnb_predictions = nb_model.transform(test_df)"}, {"cell_type": "code", "execution_count": 12, "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "rmwm2DZ4ibF5", "outputId": "0abf372e-c9ae-4c7e-a821-c15573d0f258", "tags": []}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"name": "stdout", "output_type": "stream", "text": "Logistic Regression Accuracy: 0.5000\nNaive Bayes Accuracy: 0.5000\n"}, {"name": "stderr", "output_type": "stream", "text": "[Stage 44:=============================>                            (1 + 1) / 2]\r"}, {"name": "stdout", "output_type": "stream", "text": "Logistic Regression F1 Score: 0.3333\nNaive Bayes F1 Score: 0.3333\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "# Model Evaluation (Accuracy + F1)\n\n# Accuracy\nevaluator = MulticlassClassificationEvaluator(labelCol='label', predictionCol='prediction', metricName='accuracy')\nlr_accuracy = evaluator.evaluate(lr_predictions)\nnb_accuracy = evaluator.evaluate(nb_predictions)\n\nprint(f\"Logistic Regression Accuracy: {lr_accuracy:.4f}\")\nprint(f\"Naive Bayes Accuracy: {nb_accuracy:.4f}\")\n\n# F1 Score\nf1_eval = MulticlassClassificationEvaluator(labelCol='label', predictionCol='prediction', metricName='f1')\nlr_f1 = f1_eval.evaluate(lr_predictions)\nnb_f1 = f1_eval.evaluate(nb_predictions)\n\nprint(f\"Logistic Regression F1 Score: {lr_f1:.4f}\")\nprint(f\"Naive Bayes F1 Score: {nb_f1:.4f}\")"}, {"cell_type": "markdown", "metadata": {"id": "ESF6JAx2efqJ"}, "source": "# Next Steps\nOnce the model is validated with the small dataset, you can scale this pipeline to the big dataset using Dataproc."}], "metadata": {"colab": {"provenance": []}, "kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.11.8"}}, "nbformat": 4, "nbformat_minor": 4}